<html lang="en" class=" js ">
<script>
	window._wordtune_extension_installed = true;
</script>

<head>
	
	<script>
		document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
	</script>

	<!-- For all browsers -->
	<link rel="stylesheet" href="main.css">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

	<div class="masthead">
		<div class="masthead__inner-wrap">
			<div class="masthead__menu">
				<nav id="site-nav" class="greedy-nav">

					<a class="site-logo" href="/index.html"><img src="./logos/octo_small.jpeg" alt="NES Lab"></a>

					<a class="site-title" href="/index.html">
						NES Lab
					</a>
					<ul class="visible-links">
						<li class="masthead__menu-item">
							<a href="/publications.html">Publications</a>
						</li>
						<li class="masthead__menu-item">
							<a href="/members.html">Members</a>
						</li>
						<li class="masthead__menu-item">
							<a href="/projects.html">Projects</a>
						</li>
						<li class="masthead__menu-item">
							<a href="/thesis.html">Theses</a>
						  </li>
						<li class="masthead__menu-item">
							<a href="/data.html">Data</a>
						</li>
					</ul>
					<button class="greedy-nav__toggle hidden" type="button">
						<span class="visually-hidden">Toggle menu</span>
						<div class="navicon"></div>
					</button>
					<ul class="hidden-links hidden"></ul>
				</nav>
			</div>
		</div>
	</div>

	<div style="margin: auto; max-width: 65%;">

		    <section class="page__content" itemprop="text">
      <script type="text/javascript" src="toggle.js"></script>

<style type="text/css">
a:link, a:visited, a:hover, a:active {text-decoration: none;}
.arxiv {
	font-size: small;
	background-color: red;
	color: white;
	border: 1px solid red;
	text-decoration: none;
	text-decoration-color: white;
	border-radius: 2px;
}
.openreview {
	font-size: small;
	background-color: red;
	color: white;
	border: 1px solid red;
	text-decoration: none;
	text-decoration-color: white;
	border-radius: 2px;
}
.pdf {
	font-size: small;
	background-color: blue;
	color: white;
	border: 1px solid blue;
	text-decoration: none;
	text-decoration-color: black;
	border-radius: 2px;
}
.link {
	font-size: small;
	background-color: blue;
	color: white;
	border: 1px solid blue;
	text-decoration: none;
	text-decoration-color: black;
	border-radius: 2px;
}
.journal {
	font-size: small;
	background-color: green;
	color: white;
	border: 1px solid green;
	text-decoration: none;
	text-decoration-color: white;
	border-radius: 2px;
}
.conference {
	font-size: small;
	background-color: orange;
	color: white;
	border: 1px solid orange;
	text-decoration: none;
	text-decoration-color: white;
	border-radius: 2px;
}
.workshop {
	font-size: small;
	background-color: purple;
	color: white;
	border: 1px solid purple;
	text-decoration: none;
	text-decoration-color: white;
	border-radius: 2px;
}
.bibbutton {
	font-size: small;
	background-color: black;
	color: white;
	border: 1px solid black;
	text-decoration: none;
	text-decoration-color: white;
	border-radius: 2px;
}
.bibtex {
	white-space: pre-line;
	font-size: small;
	font-family: Courier;
	background: #eeeeee;
	border: 1px dotted black;
	width: 85%;
}	
.context {
	font-style: italic;
	color: gray;
}
</style>
		<table>
		  <tbody>
		    <tr>
		      <td><a href="#forecast">Improving COVID-19 Forecasts</a></td>
		      <td><a href="#knowledge">COVID-19 Temporal Knowledge Graph</a></td>
		      <td><a href="#foundation">Building a Time-Series Foundation Model</a></td>
		      <td><a href="#multi">Multi-modal Time-Series Forecasting</a></td>
		    </tr>
		  </tbody>
		</table>
			    
		<h1 style="margin-top: 25px; color: black">Our Approach to Neuro-symbolic Computing
		</h1>
					
		<p>
		Neurosymbolic Artificial Intelligence (AI) refers to AI systems that seek to integrate (1) neural network-based methods 
		with (2) symbolic, knowledge-based approaches [<a href="https://arxiv.org/abs/2305.00813">Sheth2023</a>]. We believe 
		(1) represents low-level, and data-intensive learning 
		and (2) captures high-level, and reasoning-intensive learning. (1) is very successful in building large models for language 
		and vision, and learning patterns in the input data. However, their mostly black-box nature does not enable sufficient transparency 
		and explanability. However, a hybrid approach that incorporates (2) can better mimic human cognition (e.g., semantic memory) than 
		(1) alone and enable the explainability of model output.  
		</p>
		<p>
		Consider the task of pandemic (novel pathogens) forecasting. In this task we expect a model to predict the number of infections, hospital visits, and mortality rates in 
		the near future. Neural network-based models can learn (1) time-series patterns of a pandemic (e.g., COVID-19) from past data. Potentially 
		time-series data from other non-stationary or stationary diseases (e.g., flu, RSV, etc.) and even from other domains (e.g., stock market, 
		electricity consumption, etc.) can help to learn time-series patterns. However, this approach does not involve (2) a reasoning capability 
		(e.g., it is possible to reason that a spike in the forecast will occur if a high virulence variant has emerged). A Neuro-Symbolic AI-based 
		approach aims to incorporate both phenomena (1 and 2) to make more accurate and explainable forecasts as depicted in the figure below.
		</p>

		<img src="./pictures/Arch.png" width="900" height: auto/></br>  
			    
		<p>
		Our Neurosymbolic approach to COVID-19 forecasting involves the following individual projects:
		</p>
	 	<p>
		1- <a href="#forecast">Improving COVID-19 Forecasts</a>: In this project we study which neural network-based model performs better against traditional ensemble 
		methods published by CDC. This project also informs Project (3) below for a backbone architecture for our foundation model.
		</p>
		<p>
		2- <a href="#knowledge">COVID-19 Temporal Knowledge Graph</a>: This project aims to generate a very large Temporal Knowledge Graph by using text-extraction 
		techniques from scientific papers as well as news archives on COVID-19. This knowledge graph constitutes our symbolic representation of a hybrid model.
		</p>
		<p>
		3- <a href="#foundation">Building a Time-Series Foundation Model</a>: This project aims to build a foundation that is trained on a collection of time-series data 
		from various domains including disease, stock market, energy consumption, etc.
		</p>
		<p>
		4- <a href="#multi">Multi-modal Time-Series Forecasting</a>: In this project we aim to integrate both symbolic (2) and neural (3) approaches to build a hybrid 
		architecture for pandemic forecasting. We explore alignment as well as meta-learning among different modalities (text, image, graph) as well as different models (time series, language, knowledge). 
		</p>   
			    
		<h2 style="margin-top: 25px; color: black" id="forecast">COVID-19 Forecasts: A Comparison with CDC Models
			<a class="header-link" href="#forecast" title="Permalink">
				<span class="sr-only">Permalink</span><i class="fas fa-link"></i>
			</a>
		</h2>
					
		<p>This research project aims to enhance the accuracy of COVID-19 forecasting models. It nvolves a detailed analysis and comparison of
			COVID-19 forecasts with the models provided by the Centers for Disease Control and Prevention (CDC).</p>
		
		<a href="./pictures/Comparision.png"><img src="./logos/photo.jpeg" width="150" height="150"></a> (Click on picture icon to see a representative diagram)</br> 
		
		<p><strong>Representative Publications:</strong></p>
		<ul>
			<li>
				<p>
					S. <span onclick="window.open('https://www.researchgate.net/publication/374132791_Exploring_the_Predictive_Power_of_Correlation_and_Mutual_Information_in_Attention_Temporal_Graph_Convolutional_Network_for_COVID-19_Forecasting', '_blank')">R</span>ana, 
					N. H. Barna, and J.A. Miller
					<br />
					<b>Exploring the Predictive Power of Correlation and Mutual Information in Attention Temporal
					Graph Convolutional Network for COVID-19 Forecasting</b><br />
					<em>Proceedings of the 12th International Conference on Big Data (BigData 2023), Lecture Notes in Computer Science (LNCS, volume 14203), Honolulu, Hawaii (September 23-25, 2023) pp. 18-33</em></br>
					<a href="https://link.springer.com/chapter/10.1007/978-3-031-44725-9_2" target="_blank"><span class="arxiv">Springer</span></a>
					<span class="conference">Conference</span>
					<a onclick="toggleBibtex(Rana2023Exploring);"><span class="bibbutton">bibtex</span></a><br />
					<div class="bibtex" id="Rana2023Exploring" style="display: none;">
						@InProceedings{Rana2023Exploring,
						author = {Subas Rana, Nasid Habib Barna, and John A. Miller},
						title = {Exploring the Predictive Power of Correlation and Mutual Information in Attention Temporal Graph Convolutional Network for COVID-19 Forecasting},
						booktitle = {Proceedings of the 12th International Conference on Big Data (BigData 2023), Lecture Notes in Computer Science (LNCS, volume 14203), Honolulu, Hawaii (September 23-25, 2023) pp. 18-33},
						year = {2023},
						url = {https://link.springer.com/chapter/10.1007/978-3-031-44725-9_2},
						}
					</div>
				</p>
			</li>
			<li>
				<p>
					M. Toutiaee, X. Li, Y. Chaudhari, S. Sivaraja, A. Venkataraj,
					I. Javeri, Y. Ke, I. B. Arpinar, N. Lazar, and J. A. Miller
					<br />
					<b>Improving COVID-19 Forecasting using Exogenous Variables</b><br />
					<em>Proceedings of the 7th ACM KDD Workshop on Mining and Learning from Time Series (MileTS 2021) Virtual/Singapore (August 2021) pp. 1-6</em></br>
					<a href="https://arxiv.org/abs/2107.10397" target="_blank"><span class="arxiv">arXiv</span></a>
					<span class="conference">Conference</span>
					<a onclick="toggleBibtex(Toutee2023Improving);"><span class="bibbutton">bibtex</span></a><br />
					<div class="bibtex" id="Toutee2023Improving" style="display: none;">
						@InProceedings{Toutee2023Improving,
						author = {Mohammadhossein Toutiaee, Xiaochuan Li, Yogesh Chaudhari, Shophine Sivaraja, Aishwarya Venkataraj, Indrajeet Javeri, Yuan Ke, Ismailcem Arpinar, Nicole Lazar, and John A. Miller},
						title = {Improving COVID-19 Forecasting using Exogenous Variables},
						booktitle = {Proceedings of the 7th ACM KDD Workshop on Mining and Learning from Time Series (MileTS 2021) Virtual/Singapore (August 2021) pp. 1-6},
						year = {2021},
						url = {https://https://arxiv.org/abs/2107.10397},
						}
					</div>
				</p>
			</li>
		</ul>

		<h2 style="margin-top: 25px; color: black" id="knowledge">COVID-19 Temporal Knowledge Graph
			<a class="header-link" href="#knowledge" title="Permalink">
				<span class="sr-only">Permalink</span><i class="fas fa-link"></i>
			</a>
		</h2>
                
		<p>COVID-19 Temporal Knowledge Graph is a data structure that organize pandemic-related information in a connected graph format with time-stamps, enabling 
		researchers and healthcare professionals to easily explore and analyze diverse data sources for insights and solutions in the fight against COVID-19. 
		It provides a comprehensive, interconnected view of information, improving data integration and decision-making processes.</p>
		<p>
		A wave of progress on multivariate time series forecasting has been recent and appears to
		be heating up with the use of advanced deep learning architectures. Work has started to establish
		further improvements using Knowledge Graphs and Large Language Models. Our efforts focus on building 
		a Temporal Knowledge Graph with scientific literature, such as the CORD-19 dataset for COVID-19 and news archives. A complete
		investigation of how this can help with time series forecasting or related problems of time series
		classification or anomaly detection will take some time. Analysis of the features/factors influencing
		the course/time evolution of a pandemic may be conducted with the help of LLMs. New research can more quickly be 
		suggested to fill gaps in existing knowledge. Established knowledge can be associated with Knowledge Graphs or Temporal Knowledge Graphs.
		We are experimenting with multiple ways in which knowledge can be used to improve forecasting.	
		</p>
		
		<a href="./pictures/Knowledge_Graph.png"><img src="./logos/photo.jpeg" width="150" height="150"></a> (Click on picture icon to see a representative diagram)</br> 
	
		<p><strong>Representative Publications:</strong></p>
		<ul>
			<li>
				<p>
				J. A. Miller, N. H. Barna, S. Rana, I. B. Arpinar, and N. Liu<br /> 
				<b>Knowledge Enhanced Deep Learning: Application to Pandemic Prediction</b><br /> 
				<em>The 9th IEEE International Conference on Collaboration and Internet Computing, November 1-3, 2023, Atlanta, GA</em></br>
				<a href="https://cobweb.cs.uga.edu/~jam/papers/abs/2023_CIC/IEEECIC_2023_Miller_Talk.pptx" target="_blank"><span class="arxiv">Talk</span></a>
			    	<span class="conference">Conference</span>
				<a onclick="toggleBibtex(Miller2023Knowledge);"><span class="bibbutton">bibtex</span></a><br />
				<div class="bibtex" id="Miller2023Knowledge" style="display: none;">
					@InProceedings{Miller2023Knowledge,
						author = {J. A. Miller, N. H. Barna, S. Rana, I. B. Arpinar, and N. Liu},
						title = {Knowledge Enhanced Deep Learning: Application to Pandemic Prediction},
						booktitle = {The 9th IEEE International Conference on Collaboration and Internet Computing, November 1-3, 2023, Atlanta, GA},
						year = {2023},
						url = {https://cobweb.cs.uga.edu/~jam/papers/abs/2023_CIC/IEEECIC_2023_Miller_Talk.pptx},
						}
				</div>
				</p>	
			</li>

		</ul>

		<h2 style="margin-top: 25px; color: black" id="foundation">Building a Time-Series Foundation Model
			<a class="header-link" href="#foundation" title="Permalink">
				<span class="sr-only">Permalink</span><i class="fas fa-link"></i>
			</a>
		</h2>

		<p>
		Foundation models are being created for several modalities of data and time series data are no
		exception. During the Fall of 2023, several foundation models for time series data were created and
		tested. They show promise for providing more accurate and robust forecasts as well as potential
		for greater explainability. At our lab we are testing multiple options for backbone models as well
		as different choices for architectural elements. Although successful elements from LLMs are a good
		starting point, additional research is needed to optimize them for time series data.	
		</p>

		<p><strong>Representative Publications:</strong></p>
	        <ul>
		<li>
		<p>
		J. A. Miller, M. Aldosari, F. Saeed, N. H. Barna, S. Rana, I. B. Arpinar, and N. Liu<br />	
		<b>A Survey of Deep Learning and Foundation Models for Time Series Forecasting</b><br />
		<em>arXiv preprint arXiv:2401.13912, 2024</em></br>
					<a href="https://arxiv.org/abs/2401.13912" target="_blank"><span class="arxiv">arXiv</span></a>
					<span class="journal">Journal</span>
					<a onclick="toggleBibtex(MillerACM2024);"><span class="bibbutton">bibtex</span></a><br />
					<div class="bibtex" id="MillerACM2024" style="display: none;">
						@InProceedings{Miller:ACM2024,
						author = {JA Miller, M Aldosari, F Saeed, NH Barna, S Rana, IB Arpinar,and N Liu},
						title = {A Survey of Deep Learning and Foundation Models for Time Series Forecasting},
						booktitle = {arXiv preprint arXiv:2401.13912, 2024},
						year = {2024},
						}
					</div>
		</p>
		</li>
		</ul>
		

		<h2 style="margin-top: 25px; color: black" id="multi">Multi-modal Time-Series Forecasting
			<a class="header-link" href="#multi" title="Permalink">
				<span class="sr-only">Permalink</span><i class="fas fa-link"></i>
			</a>
		</h2>

		<p>
		We explore modeling time series data with textual data. It is challenging to build time series
		foundation models that are comparable to existing large language models since: (1) unlike natural
		languages, existing time series data lacks the inherent semantic richness; (2) the semantics in time
		series data are often heavily domain-specific (e.g., the modeling of electrocardiogram signals would
		provide little help in predicting stock prices). There are several potential benefits of the multi-model
		modeling: (1) textual data can provide essential context that is not captured in the raw time series
		data; (2) textual semantics can provide domain-specific knowledge that enhances the model’s
		interpretability; (3) textual data can introduce additional features and dimensions of variability,
		which can help in training more robust and generalizable models. In this way, text-enhanced time
		series models can be more easily transferred across different tasks (e.g., classification, forecasting,
		anomaly detection) and domains.	
		</p>

		<a href="./pictures/Knowledge_Enhanced.png"><img src="./logos/photo.jpeg" width="150" height="150"></a> (Click on picture icon to see a representative diagram)</br>
		
		<p><strong>Representative Publications:</strong></p>
		<ul>
			<li>
				<p>
				J. A. Miller, N. H. Barna, S. Rana, I. B. Arpinar, and N. Liu<br /> 
				<b>Knowledge Enhanced Deep Learning: Application to Pandemic Prediction</b><br /> 
				<em>The 9th IEEE International Conference on Collaboration and Internet Computing, November 1-3, 2023, Atlanta, GA</em></br>
				<a href="https://cobweb.cs.uga.edu/~jam/papers/abs/2023_CIC/IEEECIC_2023_Miller_Talk.pptx" target="_blank"><span class="arxiv">Talk</span></a>
			    	<span class="conference">Conference</span>
				<a onclick="toggleBibtex(Miller2cic2023);"><span class="bibbutton">bibtex</span></a><br />
				<div class="bibtex" id="Miller2cic2023" style="display: none;">
					@InProceedings{Miller2:cic2023,
						author = {J. A. Miller, N. H. Barna, S. Rana, I. B. Arpinar, and N. Liu},
						title = {Knowledge Enhanced Deep Learning: Application to Pandemic Prediction},
						booktitle = {The 9th IEEE International Conference on Collaboration and Internet Computing, November 1-3, 2023, Atlanta, GA},
						year = {2023},
						url = {https://cobweb.cs.uga.edu/~jam/papers/abs/2023_CIC/IEEECIC_2023_Miller_Talk.pptx},
						}
				</div>
				</p>	
			</li>

		</ul>
		
	</div>

	</div>

	<div id="footer" class="page__footer">
		<footer>
			<div class="page__footer-copyright">© 2023 UGA <a href="https://computing.uga.edu">School of Computing</a>
        <P>Hardman Hall, 225, <a href="https://uga.edu">University of Georgia</a>, Athens GA, 30602-7404, USA</P>
			</div>
		</footer>
	</div>

	</div>
	<script>
		function toggleBibtex(obj) { 
	console.log(obj.id);
	var id = obj.id;
	element = document.getElementById(obj.id)
	console.log(element);
	if (element.style.display == "none") {
		element.style.display="block";
	}
	else {
		element.style.display="none";
	} 
}
	</script>
	</body>
	<wordtune-read-extension></wordtune-read-extension>

</html>
